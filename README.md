# News-Popularity-Prediction
These project is part of the “Machine Learning &Advanced Machine Learning” curriculum as capstone projects at [AlmaBetter](https://www.almabetter.com/). 

#### -- Project Status: [Completed]

## Objective<br>
The main objective is to create a machine learning model to predict the popularity of news on different social media platforms such as Facebook, LinkedIn and Google Plus.

<h2> :floppy_disk: Project Files Description</h2>

<p>This Project includes 1 executable files and 1 project documentation  as follows:</p>
<h4>Executable Files:</h4>
<ul>
  <li><b>News_Popularity_Prediction.ipynb</b> - Complete notebook containing Data exploration/Data processing/transformation/model development.</li>
</ul>


<h4>Documentation:</h4>
<ul>
  <li><b>News Popularity Prediction_cohort_aravali.pptx</b> - Includes the documentation of the project.</li>
</ul>

![-----------------------------------------------------](https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/rainbow.png)

### Methods Used
* Descriptive Statistics
* Data Visualization
* Machine Learning


### Technologies
* Python
* Pandas
* Numpy
* Matplotlib
* Seaborn
* Scikit-learn
* XGBoost


## Project Description
* EDA - Performed exploratory data analysis on numerical and categorical data.
* Data Cleaning - Performed key NLP processing steps on news items such as lemmatization, POS-tagging, Named Entity Recognition, stopword removal and tokenization using spaCy.
* Feature  - Generated the optimal document-word matrix as model input by tuning parameters such as min_df, max_df, n_gram range, token_pattern in TF-IDF vectorizer.
* Model development - Tried different model and finally compared all models R2 score.

## XGBoost
The library is laser focused on computational speed and model performance, as such there are few frills. Nevertheless, it does offer a number of advanced features.

### Model Features
The implementation of the model supports the features of the scikit-learn and R implementations, with new additions like regularization. Three main forms of gradient boosting are supported:

**Gradient Boosting** algorithm also called gradient boosting machine including the learning rate.
**Stochastic Gradient** Boosting with sub-sampling at the row, column and column per split levels.
**Regularized Gradient Boosting** with both L1 and L2 regularization.
### System Features
The library provides a system for use in a range of computing environments, not least:

* **Parallelization** of tree construction using all of your CPU cores during training.
* **Distributed Computing** for training very large models using a cluster of machines.
* **Out-of-Core Computing** for very large datasets that don’t fit into memory.
* **Cache Optimization** of data structures and algorithm to make best use of hardware.

### Algorithm Features
The implementation of the algorithm was engineered for efficiency of compute time and memory resources. A design goal was to make the best use of available resources to train the model. Some key algorithm implementation features include:

* **Sparse Aware** implementation with automatic handling of missing data values.
* **Block Structure** to support the parallelization of tree construction.
* **Continued Training** so that you can further boost an already fitted model on new data.

XGBoost is free open source software available for use under the permissive Apache-2 license.


## Needs of this project

- data exploration/descriptive statistics
- data processing/cleaning
- predictive modeling

![-----------------------------------------------------](https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/rainbow.png)

<h2> :clipboard: Execution Instruction</h2>
<p>The order of execution of the program files is as follows:</p>
<p><b>1) News_Popularity_Prediction.ipynb</b></p>
<p> The News_Popularity_Prediction.ipynb contains the entire code for Data exploration/Data processing/transformation/model development </p>


![-----------------------------------------------------](https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/rainbow.png)

## Getting Started

1. Clone this repo (for help see this [tutorial](https://help.github.com/articles/cloning-a-repository/)).
2. Project documentation is being kept [here](https://github.com/Harsh1091996/News-Popularity-Prediction/blob/main/News%20Popularity%20Prediction_cohort_aravali.pptx) within this repo.  
3. Complete notebook containing Data exploration/Data processing/transformation/model development is being kept [here](https://github.com/Harsh1091996/News-Popularity-Prediction/blob/main/News_Popularity_Prediction.ipynb)
 




<!-- CREDITS -->
<h2 id="credits"> :scroll: Credits</h2>

Himanshu Sharma | Avid Learner | Data Scientist | Machine Learning Engineer | Deep Learning enthusiast

<p> <i> Contact me for Data Science Project Collaborations</i></p>


[![LinkedIn Badge](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/himan-10/)
[![GitHub Badge](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/Harsh1091996)
[![Medium Badge](https://img.shields.io/badge/Medium-1DA1F2?style=for-the-badge&logo=medium&logoColor=white)](https://harshsharma1091996.medium.com/)
[![Resume Badge](https://img.shields.io/badge/resume-0077B5?style=for-the-badge&logo=resume&logoColor=white)](https://drive.google.com/file/d/1pyTvHo2Ec4xfCszL7YkHYAwWgFi5Uf2T/view?usp=sharing)


![-----------------------------------------------------](https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/rainbow.png)
<h2> :books: References</h2>
<ul>
  <li><p>Jason Brownlee, 'Blog on XGBoost'. [Online].</p>
      <p>Available: https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/</p>
  </li>
  <li><p>Wikipedia.org, 'XGBoost'. [Online].</p>
      <p>Available: https://en.wikipedia.org/wiki/XGBoost</p>
  </li>
  <li><p>Youtube.com, 'XGBoost working'. [Online].</p>
      <p>Available: https://www.youtube.com/watch?v=OQKQHNCVf5k</p>
  </li>
  <li><p>Analytics Vidhya Agrawal@71, 'Know The Best Evaluation Metrics for Your Regression Model !'. [Online].</p>
      <p>Available: https://www.analyticsvidhya.com/blog/2021/05/know-the-best-evaluation-metrics-for-your-regression-model/</p>
  </li>
</ul>

![-----------------------------------------------------](https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/rainbow.png)


